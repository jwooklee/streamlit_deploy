import streamlit as st
import speech_recognition as sr
import os
from datetime import datetime
from streamlit.components.v1 import html
import base64

def speech_to_text(audio_file):
    r = sr.Recognizer()
    with sr.AudioFile(audio_file) as source:
        audio = r.record(source)
    try:
        text = r.recognize_google(audio, language='ko-KR')
        return text
    except sr.UnknownValueError:
        return "ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except sr.RequestError:
        return "ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

def get_audio_recorder_html():
    return """
        <div class="audio-recorder">
            <button id="recordButton" onclick="toggleRecording()">ë…¹ìŒ ì‹œì‘</button>
            <div id="recordingStatus"></div>
        </div>

        <script>
            const streamlitDoc = window.parent.document;

            function sendToStreamlit(value) {
                const event = new CustomEvent("streamlit:setComponentValue", {
                    detail: { value: value }
                });
                streamlitDoc.dispatchEvent(event);
            }

            let mediaRecorder;
            let audioChunks = [];
            let isRecording = false;

            async function toggleRecording() {
                const button = document.getElementById('recordButton');
                const status = document.getElementById('recordingStatus');
                
                if (!isRecording) {
                    try {
                        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                        mediaRecorder = new MediaRecorder(stream);
                        audioChunks = [];

                        mediaRecorder.ondataavailable = (event) => {
                            audioChunks.push(event.data);
                        };

                        mediaRecorder.onstop = async () => {
                            const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                            const reader = new FileReader();
                            reader.readAsDataURL(audioBlob);
                            reader.onloadend = function() {
                                const base64data = reader.result.split(',')[1];
                                sendToStreamlit(base64data);
                                // í˜ì´ì§€ ë¦¬ë¡œë“œë¥¼ ìœ„í•œ ì¶”ê°€ ì½”ë“œ
                                setTimeout(() => {
                                    window.parent.document.querySelector('iframe').contentWindow.location.reload();
                                }, 500);
                            };
                        };

                        mediaRecorder.start();
                        isRecording = true;
                        button.textContent = "ë…¹ìŒ ì¤‘ì§€";
                        status.textContent = "ë…¹ìŒ ì¤‘...";
                    } catch (err) {
                        console.error("Error accessing microphone:", err);
                        status.textContent = "ë§ˆì´í¬ ì ‘ê·¼ ì˜¤ë¥˜";
                    }
                } else {
                    mediaRecorder.stop();
                    isRecording = false;
                    button.textContent = "ë…¹ìŒ ì‹œì‘";
                    status.textContent = "ë…¹ìŒ ì™„ë£Œ";
                }
            }
        </script>
    """

def process_recorded_audio(base64_audio):
    try:
        # base64 ë°ì´í„°ë¥¼ WAV íŒŒì¼ë¡œ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        temp_file = f"temp_audio_{timestamp}.wav"
        
        audio_bytes = base64.b64decode(base64_audio)
        with open(temp_file, "wb") as f:
            f.write(audio_bytes)
        
        # ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        text = speech_to_text(temp_file)
        return text
    except Exception as e:
        st.error(f"ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None
    finally:
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if os.path.exists(temp_file):
            os.remove(temp_file)

def main():
    st.title("ğŸ™ï¸ ì‹¤ì‹œê°„ ìŒì„± ë…¹ìŒ ë° í…ìŠ¤íŠ¸ ë³€í™˜")
    st.write("ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ìŒì„±ì„ ë…¹ìŒí•˜ê³  í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì„¸ìš”.")
    
    # ì»´í¬ë„ŒíŠ¸ í‚¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒíƒœ ê´€ë¦¬
    audio_recorder = html(get_audio_recorder_html(), height=200, key="audio_recorder")
    
    if audio_recorder:  # ë…¹ìŒëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´
        text = process_recorded_audio(audio_recorder)
        if text:
            st.write("## ë³€í™˜ëœ í…ìŠ¤íŠ¸:")
            st.write(text)
    
    # íŒŒì¼ ì—…ë¡œë” ë¶€ë¶„ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
    uploaded_file = st.file_uploader("ë˜ëŠ” WAV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['wav'])
    if uploaded_file is not None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        temp_file = f"temp_audio_{timestamp}.wav"
        
        with open(temp_file, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        text = speech_to_text(temp_file)
        st.write("## ë³€í™˜ëœ í…ìŠ¤íŠ¸:")
        st.write(text)
        os.remove(temp_file)

if __name__ == "__main__":
    main()